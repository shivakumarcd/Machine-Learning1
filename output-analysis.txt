
							Accuracy for various subset(%)						     Saved
Type of 					build	______________________________________	Top predictors			    	     model 
Training data(0:1)		Itrn	C	time-m	Training  all     all 	    all	    	1-15				      name
________________________________	________________data_______1s______0s_______0/1s__________________________________________________
(50% : 50% = 559:559-all 1s)										
1st group (0001:0600)(3140:3698)		
				1)	0.01	3m	51.7%	  0%	    	   84.7%    1,8,2,4,13,  15,7,5,11,    14,12,10,   9,6,3  
				4)	0.05    7m	51.76	  0%	    	   84.85    1,8,2,7,4,   13,10,5,11,   15,14,12,   6,3,9
				5)	0.08    11m	51.68     0%	    	   84	    1,8,4,2,7    12,5,13,11,   14,15,10,   3,6,9

				11)	0.0821  8m	48.3	  100	    	   15.17    8,1,4,2,7,   12,5,14,11,   13,15,10,   6,3,9        
				7)	0.0825  13m	61.43	  29.46	    	   78.82    1,8,4,2,5    7,11,14,10,   13,15,12,   6,3,9
				10)	0.08252 12m     47.97	  100	    	   15.06    1,8,4,2,7   ,5,14,10,12,   11,13,15,   6,3,9   
				9)      0.08255 15m+	48.23     100%      	   15.11    1,8,4,2,7    13,11,14,15,  5,12,10     3,6.9  
				12)	0.0825				   
				8)      0.083   14.30   51.76     0         	   84.88    
				6)	0.085   12m	48.23     100%      	   15.11    1,8,4,2,7    5,12,13,15,	14,10,11    6,3,9 
				5)	0.09    13m	48.23	  100%      	   15.11    1,8,4,2,7    10,14,15,11,	5,12,13     6,3,9
				3)	0.1	15m	47.8%	  100%	    	   15.1    1,8,4,2,7,    5,10,11,13,	14,12,15,   3,6,9
				2)	0.2	30m	47.3	  100%      	   15.0    8,1,4,7,2	  13,5,11,12,	14,10,15    3,6,9  m2.txt

				Is it possible facing local minima or something? Have to try feature scaling/normalizing and then try..	
post normaliztion(PN)-----------13)	0.0821	<1m	0	  0	  0	   0	    
				14)	   0.1	<1m	0	  0	  0	   0  
				15)	   1	<1m	0	  0	  0	   0  
				16)	   10	<1m	0	  0	  0	   0  
				17)	  100	30s	0	  0	  0	   0------but "large C val tells SVM to classify correctly"- but 
				18)	  1000  30s	0	  0	  0	   0  	  this may not be a good choice for validation/test set
				19)	  .01	30s	0	  0	  0	   0
				20)	 .001	30s 	0	  0	  0	   0
				21)	.0001	5s	0	  0	  0	   0
				22)	10000	30s	0	  0	  0	   0
				Something is wrong!!!!!!!!!!!!!!!!!!!!!!!
 				*Currently, normalized, input value range: (-2.9,14.95)- and its performing way worse than earlier against my 				 expectation But for spam clissification ex6_spam.m where input was 0/1 it works very well
				*Labda = Regularization = 10,000 ==> High bias, Lambda = .0001==>High variance
					C == 1/Lambda
					Thereore C should be high to get good variance and less bias, I guess
				*note, they have used Gaussian kernel in ex6.m with SVM
				*ex6.pdf - SVN given in this example is not very efficient. For real problem, strongly recommend using highly 							   optimized SVM like LIBSVM
				**I am using ex6_spam.m classifier as base code for this problem. It uses linear Kearnel. Which BTW I dont 				  		  understand that well. It takes inputs 0/1. It supports using only various C's for training.
				**ex6 uses gaussian Kernel and it takes inputs 0-1. It also, uses various combinations of C and Sigmas for deciding
				**ex6.pdf - "to find non linear decision boounary with SVM we need to first implement Gaussian Kernel"
				*I think I got this... Linear kernel is the problem, becase in 1st part of ex6.m uses linear kernel and works well
				 for that data as it is linearly seperable. 2nd part of ex6.m uses Gaussian kernel as you can see in graph that 					 data is not linearly separable...				
	
				Next step-
				*Change linear to Gaussian Kernel... Keeping normalized data as it is...
% training=75%, % 0s=2354 1s=418
x_train = [ data(0001:2354,1:15); data(3140:3558,1:15) ];
y_train = [ data(0001:2354,16)  ; data(3140:3558,16) ];
%validation=260,  0s=130 1s=130
x_val = [ round(data(2354:2499,1:15)); round(data(3559:3698,1:15)) ];
y_val = [ data(2354:2499,16)  ; data(3559:3698,16) ];
				                             getting all 100 when mean(double(pred ~= yval)); so using ==

				.01	.01	30s	0
				.01	.03	30s	0
				.01	.1	30s	0
				.01	.3	30s	0
	Sigma .3->1==53m	.01	1	53m	0
				.01	3	62m	0
				.01	10
				.01	30
				 C	Sigma	time	train	val	1s	0s	all	Top predictors
				.03	.01	30s	0	0	0	0	0	
				.03	.03	30s	0	0	0	0	0
				.03	.1	30s	0	0	0	0	0
				.03	.3	30s	0	0	0	0	0
				.03	1	1m	0	0	0	0	0
	Sigma 1->3==		.03	3	75m	0	0	0	0	0
				.03	10
				.03	30
				-----------------
				.1	0.01
				.
				.
				
				Trying for old un-normalized data
				 C	Sigma	time	train	val	1s	0s	all	Top predictors
				.03	3	1m	100	56	80	95	93	11,10,15,2,12,5,13,14,	1,3,4,5,,6,7,8,9
				.1	.3	1m	100	56	94	83	85		same
				
x= [data(0001:0600,1:15);data(3140:3698,1:15)];
y= [data(0001:0600,16);data(3140:3698,16)];

2nd group 					
(0600:1200)(3140:3698)
														
3rd group
(1201:1800)(3140:3698)
																
4th group
(1801:2400)(3140:3698)																


best C and sigmaC =
   0.10000
   0.30000
   1.00000


					